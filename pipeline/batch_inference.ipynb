{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYfgJV2VQuUs",
        "outputId": "d8192260-a84d-45b9-a522-39f3c365f876"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install validators"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import cv2\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_v2_m as effnetv2m\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "vxX_R6ZqRaVy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======\n",
        "# device\n",
        "# ======\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "fwuqwUj3Qw6W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============\n",
        "# batch inference\n",
        "# ===============\n",
        "def batch_infer(\n",
        "    images, cls_custom=None, ci_custom=0.1, top_classes=5,\n",
        "    model_detector=\"yolov5x\", weight_detector=None,\n",
        "    model_classifier=\"effnetv2m\", weight_classifier=None\n",
        "):\n",
        "    # check image quantity\n",
        "    if len(images) != 2:\n",
        "        raise ValueError(\"only image quantity '2' supported for batch inference.\")\n",
        "\n",
        "    # check models\n",
        "    if model_detector != \"yolov5x\":\n",
        "        raise ValueError(\"only model 'yolov5x' supported for detector.\\n\")\n",
        "\n",
        "    if model_classifier != \"effnetv2m\":\n",
        "        raise ValueError(\"only model 'effnetv2m' is supported for classifier.\")\n",
        "\n",
        "    # load models\n",
        "    detector = torch.hub.load(\n",
        "        \"ultralytics/yolov5\",\n",
        "        \"custom\",\n",
        "        path=weight_detector,\n",
        "        force_reload=True\n",
        "    )\n",
        "    detector = detector.to(device)\n",
        "\n",
        "    classifier = effnetv2m()\n",
        "    classifier.load_state_dict(torch.load(weight_classifier, map_location=device), strict=False)\n",
        "\n",
        "    # detect and classify objects\n",
        "    clses, probs = [], []\n",
        "\n",
        "    for image in images:\n",
        "        # load image\n",
        "        with open(image, \"rb\") as f:\n",
        "            image = f.read()\n",
        "            arr = np.asarray(bytearray(image), dtype=np.uint8)\n",
        "            image = cv2.imdecode(arr, -1)\n",
        "\n",
        "        # check image\n",
        "        if image is None:\n",
        "            raise Exception(f\"no valid image read via 'cv2.imread()'.\\n\")\n",
        "\n",
        "        # detect objects\n",
        "        output = detector(image)\n",
        "        output = output.pandas().xyxy[0]\n",
        "        output = output[output[\"name\"] == cls_custom]\n",
        "\n",
        "        # check output\n",
        "        if output.empty:\n",
        "            raise Exception(f\"no '{cls_custom}' detected with confidence interval >= '{ci_custom}'.\")\n",
        "        else:\n",
        "            if output.shape[0] >= 2:\n",
        "                output = output.loc[[output[\"confidence\"].idxmax()]]\n",
        "\n",
        "        # calculate bounding box\n",
        "        xmin, xmax, ymin, ymax = output[\"xmin\"], output[\"xmax\"], output[\"ymin\"], output[\"ymax\"]\n",
        "\n",
        "        # crop image\n",
        "        image = image[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "\n",
        "        # configure transformation\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225]\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        # transform image\n",
        "        image = transform(image)\n",
        "        image = image.unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = torch.nn.functional.softmax(classifier(image), dim=1)\n",
        "        output = torch.topk(output, top_classes)\n",
        "\n",
        "        cls, prob = output.indices, output.values\n",
        "\n",
        "        clses.append(cls.squeeze())\n",
        "        probs.append(prob.squeeze())\n",
        "\n",
        "    cls_common = [cls for cls in clses[0] if cls in clses[1]]\n",
        "\n",
        "    indices = []\n",
        "    for i in range(len(images)):\n",
        "        inds = []\n",
        "        for cls in cls_common:\n",
        "            for ind, val in enumerate(clses[i]):\n",
        "                if val == cls:\n",
        "                    inds.append(ind)\n",
        "        indices.append(inds)\n",
        "\n",
        "    prob_common = []\n",
        "    for i in range(len(cls_common)):\n",
        "        prob_common.append(probs[0][indices[0][i]] * probs[1][indices[1][i]])\n",
        "\n",
        "    output = {\n",
        "        \"class\": cls_common,\n",
        "        \"joint probability\": prob_common\n",
        "    }\n",
        "\n",
        "    output = pd.DataFrame(output)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "VkWUJUg-Qw8e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========\n",
        "# load files\n",
        "# ==========\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path_project = \"/content/drive/MyDrive/Animal-Detector\"\n",
        "\n",
        "path_weight = os.path.join(path_project, \"weights\")\n",
        "weight_detector = os.path.join(path_weight, \"yolov5x.pt\")\n",
        "weight_classifier = os.path.join(path_weight, \"effnetv2m.pth\")\n",
        "\n",
        "image = os.path.join(path_project, \"image.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSkCxlSeQw-3",
        "outputId": "a999cea7-f363-4bb1-f220-c61b6acac66c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# test - batch inference\n",
        "# ======================\n",
        "output = batch_infer(\n",
        "    images=[image, image], cls_custom=\"Insecta\", top_classes=20,\n",
        "    weight_detector=weight_detector, weight_classifier=weight_classifier\n",
        ")\n",
        "print(f\"output\\n{output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oRTyK-xQxBK",
        "outputId": "88ded1c1-44e3-4fef-fb89-c02dc7703c81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 ðŸš€ 2023-7-13 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86254162 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output\n",
            "         class    joint probability\n",
            "0  tensor(462)  tensor(2.17979e-06)\n",
            "1  tensor(958)  tensor(2.22342e-06)\n",
            "2  tensor(539)  tensor(2.30369e-06)\n",
            "3  tensor(997)  tensor(2.47873e-06)\n",
            "4  tensor(389)  tensor(2.13701e-06)\n",
            "5  tensor(325)  tensor(2.09881e-06)\n",
            "6  tensor(313)  tensor(2.08638e-06)\n",
            "7  tensor(945)  tensor(1.98766e-06)\n"
          ]
        }
      ]
    }
  ]
}
